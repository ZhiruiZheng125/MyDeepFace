from deepface import DeepFace
import cv2
import os
import json
import pandas as pd
from datetime import datetime
import glob

def list_available_videos():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„è§†é¢‘æ–‡ä»¶å¹¶è®©ç”¨æˆ·é€‰æ‹©"""
    
    video_dir = r"C:\MyDeepFace\InputVideos"
    
    # æ”¯æŒçš„è§†é¢‘æ ¼å¼
    video_extensions = ['*.mp4', '*.avi', '*.mov', '*.mkv', '*.wmv', '*.flv']
    
    # æ‰¾åˆ°æ‰€æœ‰è§†é¢‘æ–‡ä»¶
    video_files = []
    for ext in video_extensions:
        video_files.extend(glob.glob(os.path.join(video_dir, ext)))
    
    if not video_files:
        print("âŒ åœ¨ InputVideos ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°è§†é¢‘æ–‡ä»¶")
        return None
    
    print("\nğŸ“¹ å‘ç°ä»¥ä¸‹è§†é¢‘æ–‡ä»¶:")
    print("=" * 60)
    
    for i, video_path in enumerate(video_files, 1):
        filename = os.path.basename(video_path)
        size_mb = os.path.getsize(video_path) / (1024 * 1024)
        
        # è·å–è§†é¢‘ä¿¡æ¯
        cap = cv2.VideoCapture(video_path)
        if cap.isOpened():
            fps = cap.get(cv2.CAP_PROP_FPS)
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            duration = frame_count / fps if fps > 0 else 0
            cap.release()
            
            print(f"{i}. {filename}")
            print(f"   ğŸ“ åˆ†è¾¨ç‡: {width}x{height}")
            print(f"   â±ï¸  æ—¶é•¿: {duration:.1f}ç§’")
            print(f"   ğŸ“¦ å¤§å°: {size_mb:.1f}MB")
            print()
        else:
            print(f"{i}. {filename} (æ— æ³•è¯»å–è§†é¢‘ä¿¡æ¯)")
            print()
    
    # ç”¨æˆ·é€‰æ‹©
    while True:
        try:
            choice = input(f"è¯·é€‰æ‹©è¦åˆ†æçš„è§†é¢‘ (1-{len(video_files)}) æˆ–è¾“å…¥ 'q' é€€å‡º: ").strip()
            
            if choice.lower() == 'q':
                return None
            
            choice_num = int(choice)
            if 1 <= choice_num <= len(video_files):
                selected_video = video_files[choice_num - 1]
                print(f"\nâœ… æ‚¨é€‰æ‹©äº†: {os.path.basename(selected_video)}")
                return selected_video
            else:
                print(f"âŒ è¯·è¾“å…¥ 1-{len(video_files)} ä¹‹é—´çš„æ•°å­—")
                
        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
            return None

def analyze_video_with_output(video_path=None):
    """
    åˆ†æè§†é¢‘å¹¶ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    """
    
    # å¦‚æœæ²¡æœ‰æä¾›è§†é¢‘è·¯å¾„ï¼Œè®©ç”¨æˆ·é€‰æ‹©
    if video_path is None:
        video_path = list_available_videos()
        if video_path is None:
            print("âŒ æ²¡æœ‰é€‰æ‹©è§†é¢‘æ–‡ä»¶ï¼Œç¨‹åºé€€å‡º")
            return
    
    # åŸºäºè§†é¢‘æ–‡ä»¶ååˆ›å»ºè¾“å‡ºç›®å½•
    video_name = os.path.splitext(os.path.basename(video_path))[0]
    
    # åˆ›å»ºç»Ÿä¸€çš„ä¸»è¾“å‡ºç›®å½•
    main_output_dir = "Output_Files"
    os.makedirs(main_output_dir, exist_ok=True)
    
    # ä¸ºæ¯ä¸ªè§†é¢‘åˆ›å»ºç‹¬ç«‹çš„å­ç›®å½•
    output_dir = os.path.join(main_output_dir, video_name)
    os.makedirs(output_dir, exist_ok=True)
    
    # è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆåŸºäºè§†é¢‘åç§°ï¼‰
    json_output = os.path.join(output_dir, f"emotion_analysis_{video_name}.json")
    csv_output = os.path.join(output_dir, f"emotion_analysis_{video_name}.csv")
    video_output = os.path.join(output_dir, f"analyzed_{video_name}.mp4")
    
    print("=== å¼€å§‹è§†é¢‘æƒ…æ„Ÿåˆ†æå¹¶ä¿å­˜ç»“æœ ===")
    print(f"è¾“å…¥è§†é¢‘: {video_path}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    
    # æ–¹æ³•1: é€å¸§åˆ†æå¹¶ä¿å­˜åˆ° JSON/CSV
    if os.path.exists(video_path):
        cap = cv2.VideoCapture(video_path)
        frame_count = 0
        results = []
        
        print("\nğŸ“Š æ­£åœ¨è¿›è¡Œé€å¸§åˆ†æ...")
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
                
            # æ¯éš”30å¸§åˆ†æä¸€æ¬¡ï¼ˆçº¦1ç§’ä¸€æ¬¡ï¼Œ30fpsè§†é¢‘ï¼‰
            if frame_count % 30 == 0:
                try:
                    result = DeepFace.analyze(
                        img_path=frame, 
                        actions=['emotion'], 
                        enforce_detection=False,
                        silent=True
                    )
                    
                    if result:
                        frame_result = {
                            "frame_number": frame_count,
                            "timestamp_seconds": frame_count / 30.0,  # å‡è®¾30fps
                            "dominant_emotion": result[0]['dominant_emotion'],
                            "emotions": {
                                emotion: float(score) 
                                for emotion, score in result[0]['emotion'].items()
                            }
                        }
                        results.append(frame_result)
                        
                        print(f"å¸§ {frame_count:4d} ({frame_result['timestamp_seconds']:6.1f}s): {result[0]['dominant_emotion']}")
                        
                except Exception as e:
                    print(f"å¸§ {frame_count} åˆ†æå¤±è´¥: {e}")
            
            frame_count += 1
            
            # é™åˆ¶å¤„ç†å¸§æ•°ï¼ˆå¯é€‰ï¼‰
            if frame_count > 3000:  # å¤„ç†å‰100ç§’
                break
        
        cap.release()
        
        # ä¿å­˜ç»“æœåˆ° JSON
        with open(json_output, 'w', encoding='utf-8') as f:
            json.dump({
                "video_info": {
                    "file_path": video_path,
                    "total_frames_analyzed": len(results),
                    "analysis_date": datetime.now().isoformat()
                },
                "results": results
            }, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜ç»“æœåˆ° CSV
        if results:
            df_data = []
            for result in results:
                row = {
                    "frame_number": result["frame_number"],
                    "timestamp_seconds": result["timestamp_seconds"],
                    "dominant_emotion": result["dominant_emotion"]
                }
                # æ·»åŠ æ‰€æœ‰æƒ…æ„Ÿåˆ†æ•°
                row.update(result["emotions"])
                df_data.append(row)
            
            df = pd.DataFrame(df_data)
            df.to_csv(csv_output, index=False, encoding='utf-8')
            
            print(f"\nâœ… ç»“æœå·²ä¿å­˜:")
            print(f"   ğŸ“„ JSON: {json_output}")
            print(f"   ğŸ“Š CSV:  {csv_output}")
            print(f"   ğŸ“ˆ åˆ†æäº† {len(results)} ä¸ªæ—¶é—´ç‚¹")
        
    # æ–¹æ³•2: ä½¿ç”¨ stream å‡½æ•°ç”Ÿæˆå¸¦åˆ†æç»“æœçš„è§†é¢‘
    print(f"\nğŸ¥ æ­£åœ¨ç”Ÿæˆå¸¦åˆ†æç»“æœçš„è§†é¢‘...")
    print(f"è¾“å‡ºè§†é¢‘: {video_output}")
    
    try:
        # åˆ›å»ºæ•°æ®åº“ç›®å½•
        db_path = "./temp_database"
        os.makedirs(db_path, exist_ok=True)
        
        # ä½¿ç”¨ stream å‡½æ•°ï¼Œè¿™æ¬¡æŒ‡å®šè¾“å‡ºè·¯å¾„
        DeepFace.stream(
            db_path=db_path,
            source=video_path,
            enable_face_analysis=True,
            time_threshold=2,
            frame_threshold=3,
            output_path=video_output  # æŒ‡å®šè¾“å‡ºè§†é¢‘è·¯å¾„
        )
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ç”¨æˆ·åœæ­¢äº†è§†é¢‘ç”Ÿæˆ")
    except Exception as e:
        print(f"âŒ è§†é¢‘ç”Ÿæˆå‡ºé”™: {e}")
    
    print(f"\nğŸ¯ æ‰€æœ‰è¾“å‡ºæ–‡ä»¶åº”è¯¥åœ¨: {os.path.abspath(output_dir)}")

def show_analysis_summary(video_name=None):
    """æ˜¾ç¤ºåˆ†æç»“æœæ‘˜è¦"""
    
    main_output_dir = "Output_Files"
    
    if video_name is None:
        # æŸ¥æ‰¾ Output_Files ç›®å½•ä¸­çš„æ‰€æœ‰è§†é¢‘å­ç›®å½•
        if not os.path.exists(main_output_dir):
            print("âŒ æ²¡æœ‰æ‰¾åˆ° Output_Files ç›®å½•")
            return
            
        video_dirs = [d for d in os.listdir(main_output_dir) 
                     if os.path.isdir(os.path.join(main_output_dir, d))]
        
        if not video_dirs:
            print("âŒ åœ¨ Output_Files ä¸­æ²¡æœ‰æ‰¾åˆ°åˆ†æç»“æœ")
            return
        
        # æ‰¾åˆ°æœ€æ–°çš„åˆ†æç»“æœ
        latest_dir = max(video_dirs, 
                        key=lambda x: os.path.getctime(os.path.join(main_output_dir, x)))
        
        json_pattern = os.path.join(main_output_dir, latest_dir, f"emotion_analysis_{latest_dir}.json")
        
        if os.path.exists(json_pattern):
            json_path = json_pattern
        else:
            # å¦‚æœæŒ‰æ–°å‘½åæ‰¾ä¸åˆ°ï¼Œå°è¯•æ‰¾ä»»ä½•jsonæ–‡ä»¶
            json_files = glob.glob(os.path.join(main_output_dir, latest_dir, "*.json"))
            if not json_files:
                print(f"âŒ åœ¨ {latest_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°åˆ†æç»“æœ")
                return
            json_path = json_files[0]
    else:
        json_path = os.path.join(main_output_dir, video_name, f"emotion_analysis_{video_name}.json")
    
    if os.path.exists(json_path):
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        results = data['results']
        if results:
            print(f"\nğŸ“ˆ æƒ…æ„Ÿåˆ†ææ‘˜è¦ - {os.path.basename(json_path)}:")
            print("-" * 60)
            
            # ç»Ÿè®¡ä¸»è¦æƒ…æ„Ÿ
            emotion_counts = {}
            for result in results:
                emotion = result['dominant_emotion']
                emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1
            
            # æŒ‰å‡ºç°æ¬¡æ•°æ’åº
            sorted_emotions = sorted(emotion_counts.items(), key=lambda x: x[1], reverse=True)
            
            total_points = len(results)
            for emotion, count in sorted_emotions:
                percentage = (count / total_points) * 100
                print(f"  {emotion:8s}: {count:3d} æ¬¡ ({percentage:5.1f}%)")
            
            print(f"\næ€»åˆ†æç‚¹æ•°: {total_points}")
            print(f"è§†é¢‘æ—¶é•¿: {results[-1]['timestamp_seconds']:.1f} ç§’")
            print(f"ğŸ“ ç»“æœç›®å½•: {os.path.dirname(json_path)}")
    else:
        print(f"âŒ åˆ†æç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {json_path}")

def show_all_results_overview():
    """æ˜¾ç¤ºæ‰€æœ‰åˆ†æç»“æœçš„æ¦‚è§ˆ"""
    
    main_output_dir = "Output_Files"
    
    if not os.path.exists(main_output_dir):
        print("âŒ æ²¡æœ‰æ‰¾åˆ° Output_Files ç›®å½•")
        return
    
    video_dirs = [d for d in os.listdir(main_output_dir) 
                 if os.path.isdir(os.path.join(main_output_dir, d))]
    
    if not video_dirs:
        print("âŒ åœ¨ Output_Files ä¸­æ²¡æœ‰æ‰¾åˆ°åˆ†æç»“æœ")
        return
    
    print(f"\nğŸ“ Output_Files ç›®å½•æ¦‚è§ˆ:")
    print("=" * 70)
    
    for i, video_dir in enumerate(sorted(video_dirs), 1):
        dir_path = os.path.join(main_output_dir, video_dir)
        
        # ç»Ÿè®¡æ–‡ä»¶
        files = os.listdir(dir_path)
        json_files = [f for f in files if f.endswith('.json')]
        csv_files = [f for f in files if f.endswith('.csv')]
        mp4_files = [f for f in files if f.endswith('.mp4')]
        
        print(f"{i}. ğŸ“‚ {video_dir}/")
        print(f"   ğŸ“„ JSON: {len(json_files)} ä¸ª")
        print(f"   ğŸ“Š CSV:  {len(csv_files)} ä¸ª") 
        print(f"   ğŸ¥ MP4:  {len(mp4_files)} ä¸ª")
        
        # å¦‚æœæœ‰JSONæ–‡ä»¶ï¼Œæ˜¾ç¤ºç®€è¦åˆ†æç»“æœ
        if json_files:
            try:
                json_path = os.path.join(dir_path, json_files[0])
                with open(json_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                results = data['results']
                if results:
                    # æ‰¾å‡ºä¸»è¦æƒ…æ„Ÿ
                    emotion_counts = {}
                    for result in results:
                        emotion = result['dominant_emotion']
                        emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1
                    
                    top_emotion = max(emotion_counts.items(), key=lambda x: x[1])
                    duration = results[-1]['timestamp_seconds']
                    
                    print(f"   ğŸ¯ ä¸»è¦æƒ…æ„Ÿ: {top_emotion[0]} ({(top_emotion[1]/len(results)*100):.1f}%)")
                    print(f"   â±ï¸  è§†é¢‘æ—¶é•¿: {duration:.1f}ç§’")
            except:
                print(f"   âš ï¸  æ— æ³•è¯»å–åˆ†æç»“æœ")
        
        print()

if __name__ == "__main__":
    print("ğŸ¬ DeepFace è§†é¢‘æƒ…æ„Ÿåˆ†æå·¥å…·")
    print("=" * 50)
    
    # æ˜¾ç¤ºç°æœ‰ç»“æœæ¦‚è§ˆ
    show_all_results_overview()
    
    # åˆ†æè§†é¢‘ï¼ˆä¼šè‡ªåŠ¨æç¤ºé€‰æ‹©ï¼‰
    analyze_video_with_output()
    
    # æ˜¾ç¤ºåˆ†ææ‘˜è¦
    show_analysis_summary()
    
    # å†æ¬¡æ˜¾ç¤ºæ›´æ–°åçš„æ¦‚è§ˆ
    print("\n" + "="*50)
    print("ğŸ”„ æ›´æ–°åçš„ç»“æœæ¦‚è§ˆ:")
    show_all_results_overview()#display all results overview after analysis

